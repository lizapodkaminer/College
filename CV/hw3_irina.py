# -*- coding: utf-8 -*-
"""hw2_Irina.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o0nBASlj1_kHjEoX7CVFzIG09sNBXvZ9
"""

from google.colab import drive

drive.mount('/content/gdrive')

### Usual Python tools
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import random
from matplotlib.ticker import MultipleLocator;
### For working with directory
from os import listdir
from os.path import isfile, isdir, join
import zipfile
import sys
### For timing
import time
!pip install tqdm
from tqdm.notebook import tqdm
### Skilearn tools
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
import seaborn as sns
import pandas as pd
### Open CV
!pip3 install opencv-python
import cv2
# ### Warnings ignore
# import warnings
# warnings.filterwarnings("ignore")

#func for grayscale
def rgb2gray(rgb):
    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]
    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b
    return gray

def pad(img, shape, dif):    
    res = np.full((shape[0], shape[0], shape[2]), 255)
    left_border = dif // 2
    right_border = shape[1] + left_border
    for i in range(len(img)):
        res[i][left_border:right_border] = img[i]
    return res

def padding(img):
    shape = np.shape(img)
    dif = shape[0] - shape[1]
    if dif > 0:
        return pad(img, shape, dif)
    elif dif < 0:
        img = np.moveaxis(img, [0, 1], [1, 0])
        return np.moveaxis(pad(img, np.shape(img), -dif), [0, 1], [1, 0])
    else:
        return img

# Function for downloading data to array of int from directory
def download_imgs(dir_img = '/content/gdrive/MyDrive/hhd_dataset'):
    dir_img = dir_img
    results_files = [f for f in listdir(dir_img) 
             if isdir(join(dir_img, f))]
    results_files = [int(file) for file in results_files]
    results_files.sort()
    ###
    img_files = []
    for directory in results_files:
        img = [f for f in listdir(dir_img + '/' + str(directory)) 
             if isfile(join(dir_img  + '/' + str(directory), f))] 
        img_files.append(img)
    images = []
    for i, file in tqdm(enumerate(img_files), total=len(img_files)):
        images_in_file = []
        for img_path in file:        
            # path
            path = dir_img + '/'+ str(i) +'/' + img_path
            # Using cv2.imread() method
            image = cv2.imread(path)
#             print(np.shape(image))
            image = rgb2gray(padding(image))
            image = cv2.resize(image, (32,32))
            image_neg = 255 - image
            images_in_file.append(image_neg)
        images.append(images_in_file)
    return images

#func for dividing into train, test, val
def trn_val_tst(images, train_len = 80, val_len = 10):
    train_img, val_img, test_img = [], [], []
    train_lbl, val_lbl, test_lbl = [], [], []
    for i, letter in enumerate(images):
        #taking random by shuffling
        shuffled_img = letter.copy()
        random.shuffle(shuffled_img)
        for j, img in enumerate(shuffled_img[:(len(shuffled_img) * train_len // 100)]):
            train_img.append(np.array(img))
            train_lbl.append(i)
        for j, img in enumerate(shuffled_img[(len(shuffled_img) * train_len // 100) : (len(shuffled_img) * (train_len + val_len) // 100)]):
            val_img.append(np.array(img))
            val_lbl.append(i)
        for j, img in enumerate(shuffled_img[(len(shuffled_img) * (train_len + val_len) // 100):]):
            test_img.append(np.array(img))
            test_lbl.append(i)
    return train_img, train_lbl, val_img, val_lbl, test_img, test_lbl

images = download_imgs()

train_img, train_lbl, val_img, val_lbl, test_img, test_lbl = trn_val_tst(images)

plt.imshow(train_img[0], cmap='gray')

def save_files(train_img, train_lbl, val_img, val_lbl, test_img, test_lbl):
  np.save('/content/gdrive/MyDrive/res_files/train_img', train_img, allow_pickle=True)    
  np.save('/content/gdrive/MyDrive/res_files/train_lbl', train_lbl, allow_pickle=True)
  np.save('/content/gdrive/MyDrive/res_files/val_img', val_img, allow_pickle=True)
  np.save('/content/gdrive/MyDrive/res_files/val_lbl', val_lbl, allow_pickle=True)
  np.save('/content/gdrive/MyDrive/res_files/test_img', test_img, allow_pickle=True)
  np.save('/content/gdrive/MyDrive/res_files/test_lbl', test_lbl, allow_pickle=True)

save_files(train_img, train_lbl, val_img, val_lbl, test_img, test_lbl)

def download_files():
  train_img = np.load('/content/gdrive/MyDrive/res_files/train_img.npy', allow_pickle=True)
  train_lbl = np.load('/content/gdrive/MyDrive/res_files/train_lbl.npy', allow_pickle=True)
  val_img = np.load('/content/gdrive/MyDrive/res_files/val_img.npy', allow_pickle=True)
  val_lbl = np.load('/content/gdrive/MyDrive/res_files/val_lbl.npy', allow_pickle=True)
  test_img = np.load('/content/gdrive/MyDrive/res_files/test_img.npy', allow_pickle=True)
  test_lbl = np.load('/content/gdrive/MyDrive/res_files/test_lbl.npy', allow_pickle=True)
  return train_img, train_lbl, val_img, val_lbl, test_img, test_lbl

train_img, train_lbl, val_img, val_lbl, test_img, test_lbl = download_files()

"""# Write NN"""

from __future__ import print_function, division
import numpy as np
import matplotlib.pyplot as plt
import time
import os
import copy
plt.ion()   # interactive mode

import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F
from torchsummary import summary

from numpy.core.fromnumeric import argmax
from IPython.display import clear_output

class ImageDataset(Dataset):
    def __init__(self, img, lbl, transform=None):
        img_torch = torch.as_tensor(img)
        mean_img, std_img = torch.mean(img_torch.to(float)), torch.std(img_torch.to(float))
        self.list_of_img = (img_torch - mean_img) / std_img
        self.list_of_lbl = torch.as_tensor(lbl)
        self.transform = transform

    def __len__(self):
        return len(self.list_of_lbl)

    def __getitem__(self, idx):
        image = self.list_of_img[idx]
        label = self.list_of_lbl[idx]

        if self.transform:
            image = self.transform(image)

        return image, label

class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.flatten = nn.Flatten()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(32*32, 512),
            nn.ReLU(),
            nn.Linear(512, 512),
            nn.ReLU(),
            nn.Linear(512, 27)         
        )


    def forward(self, x):
        x = self.flatten(x.to(torch.float))
        logits = self.linear_relu_stack(x)
        probs = F.softmax(logits, dim=-1)
        return probs

batch_size = 64

dataset = {
    'train': ImageDataset(img = train_img, lbl = train_lbl),
    
    'val':  ImageDataset(img = val_img, lbl = val_lbl),

    'test': ImageDataset(img = test_img, lbl = test_lbl),
    }

dataset_sizes = {x: len(dataset[x]) for x in ['train', 'val', 'test']}
dataset_sizes

dataloaders = {
    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=batch_size,
                                          shuffle=True, num_workers=2),
    'val': torch.utils.data.DataLoader(dataset['val'], batch_size=batch_size,
                                         shuffle=False, num_workers=2),
    'test': torch.utils.data.DataLoader(dataset['test'], batch_size=batch_size,
                                         shuffle=False, num_workers=2)
}

model = NeuralNetwork()
print(model)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
device

model = model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer_ft = optim.Adam(params=model.parameters())
num_epochs = 50

"""# 'Clean' Model """

def train_model(model, dataloaders, criterion, optimizer, scheduler=None, num_epochs=25):
    since = time.time()

    # Init variables that will save info about the best model
    best_model_wts = copy.deepcopy(model.state_dict())
    epoch_loss_train, epoch_loss_val = [], []
    for epoch in tqdm(range(num_epochs)):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  
            else:
                model.eval()  
                
            running_loss = 0.0
            
            for batch_img, batch_lbl in dataloaders[phase]:
                batch_img = batch_img.to(device)
                batch_lbl = batch_lbl.to(device)
                optimizer.zero_grad()
                
                with torch.set_grad_enabled(phase=='train'):

                    outputs = model(batch_img) # apply the model to the inputs. The output is the softmax probability of each class
                    torch_lbl = torch.zeros((batch_lbl.shape[0], 27), dtype=torch.float).to(device)
                    torch_lbl[np.arange(batch_lbl.shape[0]), batch_lbl] = 1              
                    loss = criterion(outputs, torch_lbl)

                    if phase == 'train':
                      
                        loss.backward() # Perform a step in the opposite direction of the gradient
                        optimizer.step() # Adapt the optimizer      
                        
                running_loss += loss.item() * batch_img.size(0)

            epoch_loss = running_loss / dataset_sizes[phase]
            if phase == 'train':
              epoch_loss_train.append(epoch_loss)
            else:
              epoch_loss_val.append(epoch_loss)

            print(f'{phase} Loss: {epoch_loss:.4f}')

            if phase == 'val' :
                best_model_wts = copy.deepcopy(model.state_dict())
        print()

    time_elapsed = time.time() - since
    print(f'Training complete in {(time_elapsed // 60):.0f}m {(time_elapsed % 60):.0f}s')
    print(f'Best Loss on val set {min(epoch_loss_val):.4f}')
    model.load_state_dict(best_model_wts)
    return model, epoch_loss_train, epoch_loss_val

model, epoch_loss_train, epoch_loss_val = train_model(model, 
                    dataloaders,
                    criterion, 
                    optimizer_ft, 
                    num_epochs=num_epochs)

plt.plot(epoch_loss_train);
plt.plot(epoch_loss_val);
plt.legend(['train', 'val'])
plt.xlabel('Epoh')
plt.ylabel('Loss')
plt.show();

"""# HW3"""

class ConvNN(nn.Module):
    def __init__(self):
        super(ConvNN, self).__init__()
        self.flatten = nn.Flatten()
        self.conv = nn.Sequential(
            self.conv_block(1, 32),
            self.conv_block(32, 64),
            self.conv_block(64, 128)
        )
        self.fc = nn.Sequential(
            nn.Flatten(),
            nn.LazyLinear(512),
            nn.ReLU(),
            nn.Dropout(p=0.5),
            nn.Linear(512, 27)
        )
    
    def conv_block(self, in_channels, out_channels, kernel_size=(3, 3), padding='same', pool_kernel_size=(2, 2), dropout=0.25):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),
            nn.ReLU(),
            nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding),
            nn.ReLU(),
            nn.MaxPool2d(pool_kernel_size),
            nn.Dropout2d(dropout)
        )

    def forward(self, x):
        x = torch.squeeze(x)
        x = x.unsqueeze(1).to(torch.float)
        x = self.conv(x)
        logits = self.fc(x)
        probs = F.softmax(logits, dim=-1)
        return probs

model = ConvNN()
model = model.to(device)
optimizer_ft = optim.Adam(params=model.parameters(), lr=1e-4)

summary(model, (32, 32))

model, epoch_loss_train, epoch_loss_val = train_model(
    model, 
    dataloaders,
    criterion, 
    optimizer_ft, 
    num_epochs=num_epochs
    
)

plt.plot(epoch_loss_train);
plt.plot(epoch_loss_val);
plt.legend(['train', 'val'])
plt.xlabel('Epoh')
plt.ylabel('Loss')
plt.show();

transform = transforms.Compose([# transforms.ToTensor(),
    # transforms.ToPILImage(),
    # transforms.ToTensor(), 
    transforms.ColorJitter(brightness=[0.2, 1.8]), 
    #transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), shear=0.2, interpolation=transforms.InterpolationMode.BILINEAR), 
    
    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])    
])

target_transform = transforms.Compose([
])

batch_size = 64

dataset_aug = {
    'train': ImageDataset(img = train_img, lbl = train_lbl, transform=transform),
    
    'val':  ImageDataset(img = val_img, lbl = val_lbl),

    'test': ImageDataset(img = test_img, lbl = test_lbl),
}

dataloaders_aug = {
    'train': torch.utils.data.DataLoader(dataset_aug['train'], batch_size=batch_size,
                                          shuffle=True, num_workers=2),
    'val': torch.utils.data.DataLoader(dataset_aug['val'], batch_size=batch_size,
                                         shuffle=False, num_workers=2),
    'test': torch.utils.data.DataLoader(dataset_aug['test'], batch_size=batch_size,
                                         shuffle=False, num_workers=2)
}

model = ConvNN()
model = model.to(device)
optimizer_ft = optim.Adam(params=model.parameters(), lr=1e-4)

summary(model, (32, 32))

model_aug, epoch_loss_train_aug, epoch_loss_val_aug = train_model(
    model, 
    dataloaders_aug,
    criterion, 
    optimizer_ft, 
    num_epochs=num_epochs    
)

plt.plot(epoch_loss_train);
plt.plot(epoch_loss_val);
plt.legend(['train', 'val'])
plt.xlabel('Epoh')
plt.ylabel('Loss')
plt.show();

"""# Accuracy"""

names = ['without aug', 'with aug']
best_val = [min(i) for i in [epoch_loss_val, epoch_loss_val_aug]]
best = np.argmin(np.array(best_val))

train_list = [epoch_loss_train, epoch_loss_train_aug]
val_list = [epoch_loss_val, epoch_loss_val_aug]

fig = plt.figure()
plt.plot(train_list[best]);
plt.plot(val_list[best]);
plt.legend(['train', 'val'])
plt.xlabel('Epoh')
plt.ylabel('Loss')
plt.title(names[best])
plt.show();
fig.savefig('/content/gdrive/MyDrive/res_files/train_val.png')

def test():
  outputs_all = torch.as_tensor([]).to(device)
  torch_lbl_all = torch.as_tensor([]).to(device)
  for batch_img, batch_lbl in dataloaders['test']:
    batch_img = batch_img.to(device)
    batch_lbl = batch_lbl.to(device)
    optimizer_ft.zero_grad()
    outputs = model(batch_img)
    outputs_all = torch.cat((outputs_all, outputs.argmax(dim=1)), 0)
    torch_lbl = torch.zeros((batch_lbl.shape[0], 27), dtype=torch.float).to(device)
    torch_lbl[np.arange(batch_lbl.shape[0]), batch_lbl] = 1 
    torch_lbl_all = torch.cat((torch_lbl_all, torch_lbl.argmax(dim=1)), 0)
  return torch_lbl_all.to(int).tolist(), outputs_all.to(int).tolist()

torch_lbl_all, outputs_all = test()

hebw_alp = ['alef', 'bet', 'gimel', 'dalet', 'hey', 'vav', 'zain', 'het', 'tet', 'yod', 'kaf', 'kaf_sofit', 'lamed', 'mem', 'mem sofit', 'nun', 'nun_sofit', 'samekh','ayin', 'pey', 'pey_sofit', 'tsadi', 'tsadi_sofit', 'kuf', 'resh', 'shin', 'taf']

def confusion_matrix(torch_lbl_all, outputs_all):
  conf_matr = np.zeros([27, 27])
  for i in range(len(torch_lbl_all)):
    conf_matr[torch_lbl_all[i], outputs_all[i]] += 1
  return conf_matr

conf_matr = confusion_matrix(torch_lbl_all, outputs_all)
pd.DataFrame(conf_matr, columns = hebw_alp, index = hebw_alp).to_csv('/content/gdrive/MyDrive/res_files/confusion_matrix.csv')
pd.read_csv('/content/gdrive/MyDrive/res_files/confusion_matrix.csv', index_col=0)

list_hebw_alp = ['alef', 'bet', 'gimel', 'dalet', 'hey', 'vav', 'zain', 'het', 'tet', 'yod', 'kaf', 'kaf_sofit', 'lamed', 'mem', 'mem sofit', 'nun', 'nun_sofit', 'samekh','ayin', 'pey', 'pey_sofit', 'tsadi', 'tsadi_sofit', 'kuf', 'resh', 'shin', 'taf', 'Avg']

#Calculating accuracy for each letter
def calculate_acc(conf_matrix):
    acc_vec = []
    for i in range(len(conf_matrix)):
        acc_vec.append(conf_matrix[i, i] / float(np.sum(conf_matrix[i, :])))
    acc_vec.append(sum(acc_vec) / 27)
    dframe = pd.DataFrame(acc_vec)
    dframe = dframe.rename(columns={0: "Accuracy"})
    dframe['Letter'] = list_hebw_alp
    dframe['Letter_id'] = range(len(list_hebw_alp))
    dframe = dframe[['Letter_id', 'Letter', 'Accuracy']]
    dframe.set_index('Letter_id', inplace=True)
    dframe.to_csv('/content/gdrive/MyDrive/res_files/acc.csv', index='Letter_id')
    return dframe

dframe = calculate_acc(conf_matr)
dframe

